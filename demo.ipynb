{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66aa6ab7",
   "metadata": {},
   "source": [
    "# Aspect-Based Sentiment Analysis using generative Language Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0196819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, GPT2LMHeadModel\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "import logging\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f8590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n",
    "    \"\"\"\n",
    "    Override logging levels of different modules based on their name as a prefix.\n",
    "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
    "\n",
    "    Args:\n",
    "        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n",
    "        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
    "          Default is `[\"\"]` to match all active loggers.\n",
    "          The match is a case-sensitive `module_name.startswith(prefix)`\n",
    "    \"\"\"\n",
    "    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n",
    "    for name in logging.root.manager.loggerDict:\n",
    "        if re.match(prefix_re, name):\n",
    "            logging.getLogger(name).setLevel(level)\n",
    "\n",
    "set_global_logging_level(logging.ERROR, [\"transformers\", \"nlp\", \"tensorflow\", \"tensorboard\", \"wandb\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815d66",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179c863c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = 7\n",
    "model_dir = '/export/share/ehosseiniasl/absa/checkpoints/restaurant_laptop/checkpoint-5000/'\n",
    "model= GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "device = torch.device(\"cuda\", index=GPU)\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eebcc4",
   "metadata": {},
   "source": [
    "# prepare input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b0dd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sequence task tokens\n",
    "\n",
    "target_token = '<|term|>'\n",
    "target_end_token = '<|endoftext|>'\n",
    "s_token = '<|review|>'\n",
    "s_end_token = '<|endofreview|>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ac2cf",
   "metadata": {},
   "source": [
    "#### more test data can be loaded from here <br> /export/share/ehosseiniasl/absa/semeval1416_restaurants_laptops_aspect_term_aspect_category_test.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5efb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence:\n",
      "<|endoftext|> <|review|> it was pleasantly uncrowded, the service was delightful, the garden adorable, the food (from appetizers to entrees) was delectable. <|endofreview|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"it was pleasantly uncrowded, the service was delightful, the garden adorable, the food (from appetizers to entrees) was delectable.\"\n",
    "sequence = f\"{target_end_token} {s_token} {text} {s_end_token}\"\n",
    "print(f\"input sequence:\\n{sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138a134",
   "metadata": {},
   "source": [
    "# run model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8e4c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model raw output:\n",
      "<|endoftext|> <|review|> it was pleasantly uncrowded, the service was delightful, the garden adorable, the food (from appetizers to entrees) was delectable. <|endofreview|> <|term|> service positive, garden positive, food positive, appetizers positive, entrees positive <|endofterm|> <|category|> ambience general positive, food quality positive, service general positive <|endofcategory|> <|endoftext|>\n",
      "\n",
      " <|term|>  service positive, garden positive, food positive, appetizers positive, entrees positive <|endofterm|> \n",
      "\n",
      " <|category|>  ambience general positive, food quality positive, service general positive <|endofcategory|> \n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = 128\n",
    "out = tokenizer.decode(model.generate(tokenizer.encode(sequence, return_tensors='pt').to(device), \n",
    "                                      max_length=max_length, \n",
    "                                      do_sample=True)[0])\n",
    "\n",
    "review = out.split(\"<|review|>\")[-1].split(\"<|term|>\")[0]\n",
    "review_text = f\"<|review|> {review}\"\n",
    "term = out.split(\"<|term|>\")[-1].split(\"<|category|>\")[0]\n",
    "term_text = f\"<|term|> {term}\"\n",
    "category = out.split(\"<|category|>\")[-1].split(\"<|endoftext|>\")[0]\n",
    "category_text = f\"<|category|> {category}\"\n",
    "\n",
    "print(f\"\\nmodel raw output:\\n{out}\")\n",
    "print(f\"\\n {term_text}\")\n",
    "print(f\"\\n {category_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5bad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
